import sys
import io
import shutil
import requests
import urllib.parse
from PIL import Image
from bs4 import BeautifulSoup

def get_terminal_size():
    size = shutil.get_terminal_size()
    return size.columns, size.lines

def pixels_to_ansi(image):
    pixels = image.load()
    width, height = image.size
    output = []
    for y in range(0, height - 1, 2):
        line = []
        for x in range(width):
            r1, g1, b1 = pixels[x, y]
            r2, g2, b2 = pixels[x, y + 1]
            line.append(f"\x1b[38;2;{r1};{g1};{b1}m\x1b[48;2;{r2};{g2};{b2}mâ–€")
        line.append("\x1b[0m")
        output.append("".join(line))
    return "\n".join(output)

def fetch_page(url, is_search=False):
    term_width, term_height = get_terminal_size()
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36","Accept-Language": "ja,en-US;q=0.9,en;q=0.8"}
    elements = [] # ãƒªãƒ³ã‚¯ã¨å…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ã‚’çµ±åˆã—ã¦ç®¡ç†
    
    try:
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # 1. å…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ (INPUT) ã‚’æ¢ã™
        for i, inp in enumerate(soup.find_all(['input', 'textarea'])):
            if inp.get('type') != 'hidden':
                name = inp.get('name') or inp.get('id') or "input"
                elements.append({"type": "INPUT", "name": name, "label": f"å…¥åŠ›: [{name}]"})

        # 2. ãƒªãƒ³ã‚¯ (A) ã‚’æ¢ã™
        for i, a in enumerate(soup.find_all('a', href=True)):
            text = a.get_text(strip=True)
            if text and len(text) > 2:
                elements.append({"type": "LINK", "url": urllib.parse.urljoin(url, a['href']), "label": text})
                if len(elements) > 15: break # ç”»é¢ã«åã¾ã‚‹ç¨‹åº¦ã«åˆ¶é™

    except Exception as e:
        print(f"è§£æã‚¨ãƒ©ãƒ¼: {e}")

    # ç”»åƒå–å¾—ï¼ˆæ¯”ç‡ 1.2ï¼‰
    api_url = f"https://s.wordpress.com/mshots/v1/{urllib.parse.quote(url)}?w=1280"
    img_ansi = ""
    try:
        img_res = requests.get(api_url, timeout=8)
        img = Image.open(io.BytesIO(img_res.content)).convert("RGB")
        pixel_h = int(term_width / 1.2) * 2
        max_h = (term_height - 12) * 2
        img_resized = img.resize((term_width, min(pixel_h, max_h)), Image.Resampling.LANCZOS)
        img_ansi = pixels_to_ansi(img_resized)
    except:
        img_ansi = "\n(ç”»åƒå–å¾—ä¸­...)\n"

    print("\x1b[2J\x1b[H", end="")
    print(img_ansi)
    print(f"\x1b[1;34m--- æ“ä½œãƒ‘ãƒãƒ« ({url[:30]}...) ---\x1b[0m")
    
    for i, el in enumerate(elements[:12]):
        color = "\033[1;33m" if el['type'] == "INPUT" else "\033[1;32m"
        print(f"{color}[{i+1}] {el['label']}\033[0m")
        
    return elements

def main():
    curr_url = "https://html.duckduckgo.com/html/"
    curr_elements = fetch_page(curr_url)
    
    while True:
        try:
            cmd = input("\nğŸ” ç•ªå·/æ¤œç´¢/URL (exitã§çµ‚äº†): ").strip()
            if cmd.lower() == 'exit': break
            
            if cmd.isdigit():
                idx = int(cmd) - 1
                if 0 <= idx < len(curr_elements):
                    el = curr_elements[idx]
                    
                    if el['type'] == "INPUT":
                        val = input(f"ğŸ“ {el['name']} ã¸ã®å…¥åŠ›å€¤: ")
                        # ç°¡æ˜“çš„ãªæ¤œç´¢å®Ÿè¡Œï¼ˆå…¥åŠ›ãƒœãƒƒã‚¯ã‚¹ãŒ1ã¤ã®ã‚µã‚¤ãƒˆç”¨ï¼‰
                        search_url = f"https://html.duckduckgo.com/html/?q={urllib.parse.quote(val)}"
                        curr_elements = fetch_page(search_url)
                    else:
                        curr_elements = fetch_page(el['url'])
            elif cmd.startswith('http'):
                curr_elements = fetch_page(cmd)
            else:
                search_url = f"https://html.duckduckgo.com/html/?q={urllib.parse.quote(cmd)}"
                curr_elements = fetch_page(search_url)
                
        except KeyboardInterrupt: break

if __name__ == "__main__":
    main()
